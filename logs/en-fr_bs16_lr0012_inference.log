[2024-11-03 04:08:37] COMMAND: translate.py --data data/en-fr/prepared/ --dicts data/en-fr/prepared/ --checkpoint-path assignments/03/output/en-fr_bs16_lr0012/checkpoints/checkpoint_best.pt --output assignments/03/output/en-fr_bs16_lr0012/translations.txt --log-file logs/en-fr_bs16_lr0012_inference.log --batch-size 1
[2024-11-03 04:08:37] Arguments: {'cuda': False, 'data': 'data/en-fr/prepared/', 'source_lang': 'fr', 'target_lang': 'en', 'max_tokens': None, 'batch_size': 1, 'train_on_tiny': False, 'arch': 'lstm', 'max_epoch': 10000, 'clip_norm': 4.0, 'lr': 0.0012, 'patience': 3, 'log_file': 'logs/en-fr_bs16_lr0012_inference.log', 'save_dir': 'assignments/03/output/en-fr_bs16_lr0012/checkpoints/', 'restore_file': 'checkpoint_last.pt', 'save_interval': 1, 'no_save': False, 'epoch_checkpoints': False, 'encoder_embed_dim': 64, 'encoder_embed_path': None, 'encoder_hidden_size': 64, 'encoder_num_layers': 1, 'encoder_bidirectional': 'True', 'encoder_dropout_in': 0.25, 'encoder_dropout_out': 0.25, 'decoder_embed_dim': 64, 'decoder_embed_path': None, 'decoder_hidden_size': 128, 'decoder_num_layers': 1, 'decoder_dropout_in': 0.25, 'decoder_dropout_out': 0.25, 'decoder_use_attention': 'True', 'decoder_use_lexical_model': 'False', 'device_id': 0, 'seed': 42, 'dicts': 'data/en-fr/prepared/', 'checkpoint_path': 'assignments/03/output/en-fr_bs16_lr0012/checkpoints/checkpoint_best.pt', 'output': 'assignments/03/output/en-fr_bs16_lr0012/translations.txt', 'max_len': 128}
[2024-11-03 04:08:37] Loaded a source dictionary (fr) with 4000 words
[2024-11-03 04:08:37] Loaded a target dictionary (en) with 4000 words
[2024-11-03 04:08:37] Loaded a model from checkpoint assignments/03/output/en-fr_bs16_lr0012/checkpoints/checkpoint_best.pt
